# NN(Neural Network)
## 概要
ニューラルネットワーク系の機械学習アルゴリズムをPythonで実装しました。

## リファレンス
### 単純パーセプトロン
- 複数個の入力層と一つの出力層で構成された、人の神経ニューロンを模して作られた線形機械学習アルゴリズムである。
- 出力層の活性化関数としてステップ関数を採用しており、二値分類タスクに対応できる。

#### パーセプトロンの収束性
- 学習サンプルが**線形に分離可能**な場合、パーセプトロン学習アルゴリズムは判別超平面を**有限回**のステップで見つけることができる。その判別超平面は学習サンプルを**完全に分類**する。
- 学習サンプルが線形分類できない場合、パーセプトロン学習アルゴリズムは**収束しない**
- 学習サンプルが線形分離可能な場合でも、ステップ数が**非常に大きくなることがある**。

#### 求め方
1. 重みベクトルの各要素をランダムに設定(初期化)
2. 学習データを上から順に選択し、重みベクトル $w$ との積から正しく分類できるかチェックする。
3. 誤識別が起こった場合、以下の式に従って重みベクトル $w$ を更新する。
  - 正例を誤識別： $w←w+φ(x)$
  - 負例を誤識別： $w←w-φ(x)$
4. 設定した繰り返し回数が終わるか、全てのサンプルが完全に分類されるまで、2~3を繰り返す。

<img width="561" alt="スクリーンショット 2022-12-04 15 28 12" src="https://user-images.githubusercontent.com/67265109/205477816-9cca6755-1356-44e5-8d2a-f95216904d89.png">


### ニューラルネットワーク(多層パーセプトロン)
- 複数個の入力層・隠れ層・出力層で構成された、パーセプトロンを多層に組み合わせて作られた非線形機械学習アルゴリズムである。
- パーセプトロンを組み合わせたことにより、非線形の予測が可能になった。
- 単純パーセプトロンでは出力層の活性化関数にステップ関数を採用していたため二値分類しかできなかったが、NNでは隠れ層にシグモイド関数、出力層にソフトマックス関数を採用することで多値分類タスクに対応できるようになった。
- 主に画像処理のタスクで活躍している。

#### 求め方
1. 重みベクトルの各要素をランダムに設定する(初期化)
2. 学習データを上から順に選択し、重みベクトル $w$ との積から正しく分類できるかチェックする。
3. 誤識別が起こった場合、**誤差逆伝播法**を用いて以下の式に従って前の層の重みベクトル $w$ を更新する。これを最初の隠れ層の重みまで実行する。
  - $w_{j,i}^{(L)} := w_{j,i}^{(L)} - \eta \frac{\partial E}{\partial w_{j,i}^{(L)}}$
    - $w_{j,i}^{(L)}$ L-1層のニューロンiからL層のニューロンjにリンクする重み
    - $E$ 誤差関数(損失関数)
    - $\eta$ ：学習率
4. 設定した繰り返し回数が終わるか、全てのサンプルが完全に分類されるまで、2~3を繰り返す。

<img width="610" alt="スクリーンショット 2022-12-04 15 30 52" src="https://user-images.githubusercontent.com/67265109/205477802-9c1415f8-6a53-4dc3-9faa-e7d1843dcc48.png">


### ディープニューラルネットワーク(DNN)


## 参考文献
- 大学の講義資料
- 本当に必要な数学だけでわかる ニューラルネットワークの理論と実装、チーム・カルポ、秀和システム(2019)

![Unknown](https://user-images.githubusercontent.com/67265109/205446198-f870931f-1c93-486e-a7ce-d444338b592d.jpeg)
