# ML_Learning

## 概要
機械学習の文脈で勉強した内容をPythonで実装したプログラム集です。

## 内容
## 教師あり学習
### [説明可能な人工知能(XAI)](https://github.com/ARAN1218/ML_Learning/tree/main/XAI)
- ブラックボックスな機械学習の解釈手法についてPythonで実装しました。
- 各手法について、使用上の注意等の簡単な説明をつけています。

### [アンサンブル学習(Ensemble)](https://github.com/ARAN1218/ML_Learning/tree/main/Ensemble)
- アンサンブル学習のメタアルゴリズム(バギング、ブースティング、スタッキング)についてPythonで実装しました。
- 各種アンサンブル学習を組み合わせて作った新しいメタアルゴリズムについても記述しております。

### [ニューラルネットワーク系(NN)](https://github.com/ARAN1218/ML_Learning/tree/main/NN)
- ニューラルネットワーク系の機械学習アルゴリズムについてPythonで実装しました。
- 活性化関数等の各種パラメータ調整が可能です。

### [K近傍法(KNN)](https://github.com/ARAN1218/ML_Learning/tree/main/KNN)
- 機械学習アルゴリズムの一種であるK近傍法について、分類と回帰の両方をPythonで実装しました。
- 類似度を求める距離を4種類から選択できるようにしています。(ユークリッド、マンハッタン等)

### [一般化線形モデル(GLM)](https://github.com/ARAN1218/ML_Learning/tree/main/GLM)
- 種々の一般化線形モデルについて、Pythonで実装しました。
- 種々の確率分布を仮定したモデルは、目的に応じて使い分けることで強力な分析手法になります。

### [ナイーブベイズ](https://github.com/ARAN1218/ML_Learning/tree/main/Naive_bayes)
-機械学習アルゴリズムの一種であるナイーブベイズについて、Pythonで実装しました。
- 特徴量の独立性を仮定し、単純に各クラスに分類される確率を計算して分類する機械学習アルゴリズムで、計算の計量化や増分学習で活躍します。

### その他(予定)
- 重回帰分析
  - 加重最小二乗法(WLS)
  - 一般化最小二乗法(GLS)
  - 再帰的最
  - 小二乗法(Recursive LS)
- 順序ロジスティック回帰
- プロビット回帰
- ポアソン回帰
- フィッシャーの線形判別
- XGBoost
- LightGBM
- CatBoost
- スタッキング(Stacking)
- ブレンディング(Blending)
- バンピング(Bumping)
- M-plots
- ALE
- Anchor
- LIME
- RBFネットワーク
- SVM
- SVR
- ディープニューラルネットワーク(DNN)

## 教師なし学習
- 階層型クラスタリング
  - ユークリッド距離＊ウォード法など

- 非階層型クラスタリング
  - k-meansなど

- 主成分分析
  - PCAなど



