# GLM(Generalized Linear Model)
## 概要
一般化線形モデル(GLM)について、Pythonで実装しました。

GLMの3要素
1. 目的変数は理論上良い性質を持つとされる**指数分布族**(正規分布、2項分布、ポアソン分布等)に従う。
2. 説明変数は**線形的**にモデルに関与するとして、以下のように定義される。
$$y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + ... + \beta_n x_{in}$$
3. 線形予測子は目的変数の平均 $\mu = E[Y_i]$ の関数
$$g(\mu_i) = y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + ... + \beta_n x_{in}$$
  と仮定される。線形予測子と平均の関係を規定する関数 $g(・)$ は**連結関数**と呼ばれ、通常滑らかで単調性を持つものと仮定される。

## 注意点
- 線形予測子における線形性はパラメータのみに求められるものであり、共変量 $x$ に対しては求められない。
  - ex.) 線形予測子に $\beta_i^{2}$ を含めるのはダメだが、説明変数にあるデータ $x_1$ の任意の関数である $x_1^{3}, \log{x_1}$ 等を含めても良い。

# リファレンス
## 全体
| 一般化線形モデル | 誤差構造 | 連結関数 | 用途 |
| :---: | :---: | :---: | :---: |
| 重回帰分析 | 正規分布 | Yの平均に対しての恒等連結関数( $E(Y) = \eta$ ) | 線形回帰による分析 |
| ロジスティック回帰 | 二項分布 | ロジット関数( $\log \frac{\pi_i}{1 - \pi_i}$ ) | 主に線形二値分類による分析 |

※線形予測子は使用する説明変数によって変化する。

## 重回帰分析(正規分布)
- 目的変数 $Y$ は互いに独立で**正規分布**に従う。
$$Y 〜 N(\mu_i, \sigma^2)$$
- 説明変数 $x$ の線型結合で線形予測子を定める。
$$\eta = x'\beta = \beta_0 + \sum_{i=1}^{p}x_i \beta_i$$
- 目的変数 $Y$ の平均に対して、恒等連結関数を規定する。
$$E(Y) = \eta$$
- 解釈性の高さや回帰診断等で分析手法として用いられることが多い。

#### 線形モデルの仮定
1. 線形性の仮定： $E(Y_i | X) = x_i'\beta (i=1,...n)$
2. 等分散の仮定： $Var(Y_i | X) = \sigma^2 (i=1,...n)$
3. 無相関の仮定： $Cov(Y_i, Y_j | X) = 0 (i \neq j)$
4. 正規性の仮定： $(Y | X) = N(0, \sigma^2 I)$

### 最小二乗法(OLS)
- 目的変数との二乗誤差 $L = \sum_{i=1}^{n}(y_i - ax_i - b)^2$ を小さくする重みベクトルを求めるというシンプルな方法。
- 勾配降下法のように近侍ではなく、学習を繰り返す必要がないため計算コストが非常に低い。

<img width="318" alt="スクリーンショット 2022-12-10 1 46 48" src="https://user-images.githubusercontent.com/67265109/206750929-7bf4d3c2-c746-48ce-9c51-736b6e0ae430.png">


### 加重最小二乗法(WLS)


### 一般化最小二乗法(GLS)


### 再帰的最小二乗法(Recursive LS)


## ロジスティック回帰(二項分布)
### 二項ロジスティック回帰
- 二値分類タスクに用いられる一般化線形モデルの一種。
- 連結関数としてロジット関数、誤差構造として二項分布を持つ。
- パラメータの推定には最小二乗法ではなく、最尤推定法を用いる。

$$\log \frac{\pi_i}{1 - \pi_i} = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + ... + \beta_n x_{in}$$
$$(E[Y_i]=\pi_i, 0<\pi_i<1)$$

<img width="480" alt="スクリーンショット 2022-12-09 0 45 58" src="https://user-images.githubusercontent.com/67265109/206492276-9759b6d7-f32d-4e1d-975d-1cc68ab1d41b.png">
<img width="221" alt="スクリーンショット 2022-12-09 0 46 29" src="https://user-images.githubusercontent.com/67265109/206492427-e377a2d3-7eef-45c0-8ecd-742fd3bbf1d7.png">


### 順序ロジスティック分析
- 二項ロジスティック回帰の目的変数を3つ以上の順序尺度データに対応させたもの。
  - 目的変数が「悪い」「普通」「良い」であった場合、「悪い vs. 普通&良い」と「悪い&普通 vs. 良い」のモデルを作成する。
  - この時の**偏回帰係数は両モデルで同じ**であり、切片と残差のみ異なる。
- リンク関数としてロジット関数、誤差構造としてベルヌーイ分布を持つ。
- パラメータの推定には最小二乗法ではなく、最尤推定法を用いる。


### 多項ロジスティック回帰
- 二項ロジスティック回帰の目的変数を3つ以上のカテゴリカルデータ(名義尺度)に対応させたもの。
- リンク関数としてロジット関数、誤差構造としてベルヌーイ分布を持つ。
- パラメータの推定には最小二乗法ではなく、最尤推定法を用いる。

<img width="481" alt="スクリーンショット 2022-12-07 23 45 10" src="https://user-images.githubusercontent.com/67265109/206491511-3bbd9e18-e7f2-4aa0-a5df-1c3ccdc97a16.png">
<img width="433" alt="スクリーンショット 2022-12-08 23 43 43" src="https://user-images.githubusercontent.com/67265109/206491572-2d422cea-44d3-4a96-b2ab-d5257014a7a6.png">


## ポアソン回帰(ポアソン分布)



## 参考文献
- 日本統計学会公式認定 統計検定準1級対応 統計学実践ワークブック　日本統計学会(編)　学術図書出版社(2020)
- データ解析のための統計モデリング入門――一般化線形モデル・階層ベイズモデル・MCMC (確率と情報の科学)　久保 拓弥　岩波書店(2012)
- 一般化線形モデル (統計解析スタンダード)　国友直人ほか　朝倉書店(2016)

![Unknown](https://user-images.githubusercontent.com/67265109/206609074-4f8a3af7-eae2-44d4-be88-79ad1d4966e7.jpeg)
![Unknown](https://user-images.githubusercontent.com/67265109/206610066-2d22f292-6c39-4061-98bf-36bfea356589.jpeg)
![Unknown](https://user-images.githubusercontent.com/67265109/206610075-0c70f90a-eac2-4911-9d5d-f07bd7e4ac2e.jpeg)

