# GLM(Generalized Linear Model)
## 概要
一般化線形モデル(GLM)について、Pythonで実装しました。

GLMの3要素
1. 目的変数は理論上良い性質を持つとされる**指数分布族**(正規分布、2項分布、ポアソン分布等)に従う。
2. 説明変数は**線形的**にモデルに関与するとして、以下のように定義される。
$$y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + ... + \beta_n x_{in}$$
3. 線形予測子は目的変数の平均 $\mu = E[Y_i]$ の関数
$$g(\mu_i) = y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + ... + \beta_n x_{in}$$
  と仮定される。線形予測子と平均の関係を規定する関数 $g(・)$ は**連結関数**と呼ばれ、通常滑らかで単調性を持つものと仮定される。

## 注意点
- 線形予測子における線形性はパラメータのみに求められるものであり、共変量 $x$ に対しては求められない。
  - ex.) 線形予測子に $\beta_i^{2}$ を含めるのはダメだが、説明変数にあるデータ $x_1$ の任意の関数である $x_1^{3}, \log{x_1}$ 等を含めても良い。
  - ○： $y = \beta_0 + \beta_1 x_1 + \beta_2 x_1^2 + \beta_3 x_2 + \beta_4 \sin{x_2}$
  - ✖︎： $y = x_1 K^{x_2} L^{x_3}$
    - ただし、両辺の対数をとって変数変換することで線形モデルとして扱える。( $\log{y} = \log{x_1} + x_2\log{K} + x_3\log{L}$ )

# リファレンス
## 全体
| 一般化線形モデル | 誤差構造 | 連結関数 | 目的変数の値 | 目的変数の範囲 | 目的変数の平均と分散の関係 |
| :---: | :---: | :---: | :---: | :---: | :---: |
| 重回帰分析 | 正規分布 | Yの平均に対しての恒等連結関数( $E(Y) = \eta$ ) | 連続値 | [-∞,+∞] | 無関係 |
| ガンマ回帰 | ガンマ分布 | 対数関数( $\log{\pi}$ )? | 連続値 | [0,+∞] | 分散は平均の関数 |
| ロジスティック回帰 | 二項分布 | ロジット関数( $\log \frac{\pi_i}{1 - \pi_i}$ ) | 離散値 | [0,N] | 分散は平均の関数 |
| プロビット回帰 | 標準正規分布 | プロビット関数(標準正規分布の分布関数の逆関数)( $\phi(x) = \dfrac{1}{\sqrt{2\pi\sigma}}\exp(-\dfrac{(x-\mu)^ 2}{2\sigma^ 2})$ ) | 離散値 | [0,N] | 無関係 |
| ポアソン回帰 | ポアソン分布 | 対数関数( $\log{\pi}$ ) | 離散値 | [0,+∞] | 同値 |

※線形予測子は使用する説明変数によって変化する。

## 重回帰分析(正規分布)
- 目的変数 $Y$ は互いに独立で**正規分布**に従う。
$$Y 〜 N(\mu_i, \sigma^2)$$
- 説明変数 $x$ の線型結合で線形予測子を定める。
$$\eta = x'\beta = \beta_0 + \sum_{i=1}^{p}x_i \beta_i$$
- 目的変数 $Y$ の平均に対して、恒等連結関数を規定する。
$$E(Y) = \eta$$
- 解釈性の高さや回帰診断等で分析手法として用いられることが多い。
- ガンマ分布と違い、目的変数が負の値を取る場合にも対応している。
- 説明変数の単位が異なると偏回帰係数の解釈に差が出てしまうため、分析時は標準化・正規化等でスケーリングして「一標準偏差当たり」の土俵に持っていく。

#### 線形モデルの仮定
1. 線形性の仮定： $E(Y_i | X) = x_i'\beta (i=1,...n)$
2. 等分散の仮定： $Var(Y_i | X) = \sigma^2 (i=1,...n)$
3. 無相関の仮定： $Cov(Y_i, Y_j | X) = 0 (i \neq j)$
4. 正規性の仮定： $(Y | X) = N(0, \sigma^2 I)$

### 最小二乗法(OLS)
- 目的変数との二乗誤差 $L = \sum_{i=1}^{n}(y_i - ax_i - b)^2$ を小さくする重みベクトルを求めるというシンプルな方法。
- 勾配降下法のように近侍ではなく、学習を繰り返す必要がないため計算コストが非常に低い。

<img width="318" alt="スクリーンショット 2022-12-10 1 46 48" src="https://user-images.githubusercontent.com/67265109/206750929-7bf4d3c2-c746-48ce-9c51-736b6e0ae430.png">


### 加重最小二乗法(WLS)


### 一般化最小二乗法(GLS)


### 再帰的最小二乗法(Recursive LS)


## ガンマ回帰(ガンマ分布)
- 目的変数の値が0以上の連続値である場合に考慮すべき一般化線形モデルの一種。
  - 正規分布は負の値も考慮するため、そこで大きく差別化している。
- 連結関数として対数関数、誤差構造としてガンマ分布を持つ。
- パラメータの推定には最小二乗法ではなく、最尤推定法を用いる。


## ロジスティック回帰(二項分布)
### 二項ロジスティック回帰
- 二値分類タスクに用いられる一般化線形モデルの一種。
- 連結関数としてロジット関数、誤差構造として二項分布を持つ。
- パラメータの推定には最小二乗法ではなく、最尤推定法を用いる。
- プロビット回帰よりも偏回帰係数の解釈が容易であり、こちらが用いられることが多い。

$$\log \frac{\pi_i}{1 - \pi_i} = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + ... + \beta_n x_{in}$$
$$(E[Y_i]=\pi_i, 0<\pi_i<1)$$

<img width="480" alt="スクリーンショット 2022-12-09 0 45 58" src="https://user-images.githubusercontent.com/67265109/206492276-9759b6d7-f32d-4e1d-975d-1cc68ab1d41b.png">
<img width="221" alt="スクリーンショット 2022-12-09 0 46 29" src="https://user-images.githubusercontent.com/67265109/206492427-e377a2d3-7eef-45c0-8ecd-742fd3bbf1d7.png">


### 順序ロジスティック分析
- 二項ロジスティック回帰の目的変数を3つ以上の順序尺度データに対応させたもの。
  - 目的変数が「悪い」「普通」「良い」であった場合、「悪い vs. 普通&良い」と「悪い&普通 vs. 良い」のモデルを作成する。
  - この時の**偏回帰係数は両モデルで同じ**であり、切片と残差のみ異なる。
- リンク関数としてロジット関数、誤差構造としてベルヌーイ分布を持つ。
- パラメータの推定には最小二乗法ではなく、最尤推定法を用いる。

<img width="508" alt="スクリーンショット 2023-01-25 0 28 37" src="https://user-images.githubusercontent.com/67265109/214336112-b4f5acb7-8643-4751-a8fb-aea1037d952a.png">
<img width="181" alt="スクリーンショット 2023-01-25 0 28 46" src="https://user-images.githubusercontent.com/67265109/214336093-472f3543-afda-4525-9426-7fcde8f0ec50.png">



### 多項ロジスティック回帰
- 二項ロジスティック回帰の目的変数を3つ以上のカテゴリカルデータ(名義尺度)に対応させたもの。
- リンク関数としてロジット関数、誤差構造としてベルヌーイ分布を持つ。
- パラメータの推定には最小二乗法ではなく、最尤推定法を用いる。

<img width="502" alt="スクリーンショット 2023-01-25 0 30 23" src="https://user-images.githubusercontent.com/67265109/214336567-379edaa0-f804-4068-89d4-f104e51ae001.png">
<img width="437" alt="スクリーンショット 2023-01-25 0 30 33" src="https://user-images.githubusercontent.com/67265109/214336572-98239af4-986e-4ffe-bd9f-fdba5deed291.png">


## プロビット回帰
- 二値分類タスクに用いられる一般化線形モデルの一種。
- リンク関数としてプロビット関数、誤差構造として標準正規分布を持つ。
- パラメータの推定には最小二乗法ではなく、最尤推定法を用いる。


## ポアソン回帰(ポアソン分布)
- カウントデータタスクに用いられる一般化線形モデルの一種。
- リンク関数として対数関数、誤差構造としてポアソン分布を持つ。
- パラメータの推定には最小二乗法ではなく、最尤推定法を用いる。
- 平均と分散が同値であると判断できない場合、負の二項回帰を検討する余地がある。

<img width="438" alt="スクリーンショット 2023-01-28 0 53 04" src="https://user-images.githubusercontent.com/67265109/215129762-c1a419b6-be00-46c0-8e8a-48613c64353f.png">
<img width="214" alt="スクリーンショット 2023-01-28 0 53 15" src="https://user-images.githubusercontent.com/67265109/215129772-d34d8ee2-9f05-49cf-83e7-fe19b7fbe75a.png">


## 参考文献
- 日本統計学会公式認定 統計検定準1級対応 統計学実践ワークブック　日本統計学会(編)　学術図書出版社(2020)
- データ解析のための統計モデリング入門――一般化線形モデル・階層ベイズモデル・MCMC (確率と情報の科学)　久保 拓弥　岩波書店(2012)
- 一般化線形モデル (統計解析スタンダード)　国友直人ほか　朝倉書店(2016)

![Unknown](https://user-images.githubusercontent.com/67265109/206609074-4f8a3af7-eae2-44d4-be88-79ad1d4966e7.jpeg)
![Unknown](https://user-images.githubusercontent.com/67265109/206610066-2d22f292-6c39-4061-98bf-36bfea356589.jpeg)
![Unknown](https://user-images.githubusercontent.com/67265109/206610075-0c70f90a-eac2-4911-9d5d-f07bd7e4ac2e.jpeg)

