# アンサンブル学習アルゴリズム
## 概要
機械学習におけるアンサンブル学習アルゴリズムを実装しました。

## リファレンス
### 決定木(Decision Tree)
- ノンパラメトリックな機械学習アルゴリズムの一種
- やっていることは「データを分割する」ということだけで、実は予測はしていない。
  - 予測はデータを分割した先（葉）に仕込んだ線形回帰等の機械学習アルゴリズムによって行われる。
  - いくつかの機械学習アルゴリズムを組み合わせて使うため、アンサンブル学習の一種として見ることもできる。
  - 同じようなデータに分割した後に学習させるため、これらは非線形を捉えられる。
- データをどのように分けたのかを可視化することにより、非常に解釈性の高いモデルとなっている。
- 決定木は過学習しやすいため、プルーニング（枝刈り）等の手法が提案されている。
- 低バイアス・高バリアンスのモデルであるため、各種アンサンブル学習の基本アルゴリズムとして採用されている。

#### アルゴリズム
1. ある説明変数を選択し、その中から最もデータを分割できる値を探索する。  
(データが分割できた尺度として、標準偏差(回帰)・ジニ不純度(分類)・Information gain(分類)等を計算する。)
3. 1で発見した値でデータの分岐点を作成する。
4. 指定した深さ(max_depth)までノードが伸びた時点で分岐を止め、葉に指定した機械学習アルゴリズムで。
5. 必要に応じてプルーニングを行うために、あまり分割できていない分岐点を探索・置換する。
<img width="262" alt="スクリーンショット 2022-12-13 14 41 39" src="https://user-images.githubusercontent.com/67265109/207239017-7b98e479-559f-410d-b09f-7389b2889448.png">
<img width="285" alt="スクリーンショット 2022-12-13 15 02 44" src="https://user-images.githubusercontent.com/67265109/207238997-db386c2a-afad-4fe2-be98-a1f39bde59fc.png">


### バギング(Bagging)
- 複数の異なる機械学習アルゴリズムを学習させて、それらの予測値の平均を取ることで確率的に汎化誤差を減少させるアルゴリズム。
  - 分類であれば多数決投票やクラスの所属確率、回帰であれば単純な平均値を指す。
- 名称はBootstrap AGGrigatINGから来ている。
- 採用する機械学習アルゴリズムは何でも良く、性能が低いモデル程伸び代がある。

#### アルゴリズム
ある機械学習モデルの残差を求める関数を $f$ と置くと、以下の関係が成り立つ。  
$$Ef^{2}(x) \geq [Ef(x)]^{2}$$
この式から、「複数モデルの予測値の平均のMAEは、複数モデルの予測値のMAEの平均**以下**である」事が分かる。つまり、予測の平均値をとったほうが汎化誤差が小さくなる。そして、誤差がどの程度小さくなるかは「採用したモデル同士の相関関係の低さ」による。  
より異なったモデルの平均の方が汎化誤差が低く、似たようなモデルならあまり変わらない。理想は各モデルの性能が高く、それぞれの相関が低いことである。  
この「相関の低い」モデルを作成するため、このアルゴリズムでは各モデルの学習毎にブートストラップ法によって重複を許した任意の数の学習データを生成・適用する。ブートストラップ法を用いることで統計的ないくつかの異なる機械学習モデルの誤差の平均は、元々のデータに対するモデルの誤差を近似することになるため、バギングはその汎化誤差以下になることが期待できる。

<img width="355" alt="スクリーンショット 2022-12-13 23 32 21" src="https://user-images.githubusercontent.com/67265109/207361748-b682c8b4-0ede-484b-8822-1db054c2bc66.png">
<img width="574" alt="スクリーンショット 2022-12-13 23 32 49" src="https://user-images.githubusercontent.com/67265109/207361771-32038e38-8332-46a7-bc23-8d87efb6cb2e.png">


### ランダムフォレスト(Random Forest)


### ブースティング(Boosting)


### アダブースティング(AdaBoosting)


### XGBoost


### LightGBM


### Catboost


### スタッキング(Stacking)


### ブレンディング(Blending)


### バンピング(Bumping)


### バギングをブースティングしてスタッキングする（？）


## 参考文献
- 作ってわかる! アンサンブル学習アルゴリズム入門、坂本俊之、C&R研究所(2019)

![Unknown](https://user-images.githubusercontent.com/67265109/207372585-25c2cedf-cfc0-40f9-876c-74790433cb08.jpeg)
