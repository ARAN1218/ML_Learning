# アンサンブル学習アルゴリズム
## 概要
機械学習におけるアンサンブル学習アルゴリズムを実装しました。

## リファレンス
### 決定木(Decision Tree)
- ノンパラメトリックな機械学習アルゴリズムの一種
- やっていることは「データを分割する」ということだけで、実は予測はしていない。
  - 予測はデータを分割した先（葉）に仕込んだ線形回帰等の機械学習アルゴリズムによって行われる。
  - いくつかの機械学習アルゴリズムを組み合わせて使うため、アンサンブル学習の一種として見ることもできる。
  - 同じようなデータに分割した後に学習させるため、これらは非線形を捉えられる。
- データをどのように分けたのかを可視化することにより、非常に解釈性の高いモデルとなっている。
- 決定木は過学習しやすいため、プルーニング（枝刈り）等の手法が提案されている。
- 低バイアス・高バリアンスのモデルであるため、各種アンサンブル学習の基本アルゴリズムとして採用されている。

#### アルゴリズム
1. ある説明変数を選択し、その中から最もデータを分割できる値を探索する。  
(データが分割できた尺度として、標準偏差(回帰)・ジニ不純度(分類)・Information gain(分類)等を計算する。)
3. 1で発見した値でデータの分岐点を作成する。
4. 指定した深さ(max_depth)までノードが伸びた時点で分岐を止め、葉に指定した機械学習アルゴリズムで。
5. 必要に応じてプルーニングを行うために、あまり分割できていない分岐点を探索・置換する。
<img width="262" alt="スクリーンショット 2022-12-13 14 41 39" src="https://user-images.githubusercontent.com/67265109/207239017-7b98e479-559f-410d-b09f-7389b2889448.png">
<img width="285" alt="スクリーンショット 2022-12-13 15 02 44" src="https://user-images.githubusercontent.com/67265109/207238997-db386c2a-afad-4fe2-be98-a1f39bde59fc.png">


### バギング(Bagging)
- 複数の異なる機械学習アルゴリズムを学習させて、それらの予測値の平均を取ることで確率的に汎化誤差を減少させるアルゴリズム。
  - 分類であれば多数決投票やクラスの所属確率、回帰であれば単純な平均値を指す。
- 名称はBootstrap AGGrigatINGから来ている。
- 採用する機械学習アルゴリズムは何でも良く、性能が低いモデル程伸び代がある。

#### アルゴリズム
ある機械学習モデルの残差を求める関数を $f$ と置くと、以下の関係が成り立つ。  
$$Ef^{2}(x) \geq [Ef(x)]^{2}$$
この式から、「複数モデルの予測値の平均のMAEは、複数モデルの予測値のMAEの平均**以下**である」事が分かる。つまり、予測の平均値をとったほうが汎化誤差が小さくなる。そして、誤差がどの程度小さくなるかは「採用したモデル同士の相関関係の低さ」による。  
より異なったモデルの平均の方が汎化誤差が低く、似たようなモデルならあまり変わらない。理想は各モデルの性能が高く、それぞれの相関が低いことである。  
この「相関の低い」モデルを作成するため、このアルゴリズムでは各モデルの学習毎にブートストラップ法によって重複を許した任意の数の特徴量を生成・適用する。ブートストラップ法を用いることで統計的ないくつかの異なる機械学習モデルの誤差の平均は、元々のデータに対するモデルの誤差を近似することになるため、バギングはその汎化誤差以下になることが期待できる。  
また、バギングは個々の機械学習モデルの学習は別々に行える（並列処理が可能である）ことから、計算が高速に行える。

<img width="355" alt="スクリーンショット 2022-12-13 23 32 21" src="https://user-images.githubusercontent.com/67265109/207361748-b682c8b4-0ede-484b-8822-1db054c2bc66.png">
<img width="574" alt="スクリーンショット 2022-12-13 23 32 49" src="https://user-images.githubusercontent.com/67265109/207361771-32038e38-8332-46a7-bc23-8d87efb6cb2e.png">


### ランダムフォレスト(Random Forest)
- バギングの「学習データ数が多いと、結局似たようなモデルが出来上がってしまい、各モデルの相関が高くなってしまう」という弱点を克服したバギングの応用アルゴリズム。
- 学習データをバギングによってランダムに生成・適用するのみならず、使用する「特徴量の次元数」をもランダムで決定することで、より相関の低い決定木モデルを生成できるという理屈のもと作られたアルゴリズムである。
- 現在も予測性能の高い機械学習アルゴリズムとして知られている。
- 機械学習モデルに決定木を採用した理由は、決定木が低バイアス・高バリアンスのモデルだからである。
- バギングは並列処理が可能であることから、それなりに高速・高精度の機械学習アルゴリズムとして運用できる。
- ランダムフォレストは採用されなかったデータを用いて**特徴量重要度**というものを計算できる。ブートストラップによって選ばれない学習データは統計的に全体の約36%あり、そのデータをテストデータとして[PFI](https://github.com/ARAN1218/ML_Learning/tree/main/XAI#pfipermutation-feature-importance)を計算することで求める。また、単に各決定木のジニ不純度の減少率を平均したものも特徴量重要度として計算される。

#### アルゴリズム
1. 決定木モデルを用意し、初期化する。
2. ある決定木モデルに対して、全特徴量の中からある次元だけランダムに抽出し、それだけを学習に用いると決める。
3. 2で決めた次元の特徴量から、ブートストラップ法によってランダムに重複を許した任意の数の特徴量を生成・適用する。
4. 2,3の手順を指定の本数の決定木モデルに対して行う。
5. 予測の際は全モデルの平均値を最終的な出力とする。

<img width="578" alt="スクリーンショット 2022-12-14 1 47 09" src="https://user-images.githubusercontent.com/67265109/207393610-4b415e0d-4331-4ceb-89a9-75acb6d53f94.png">


### アダブースティング(AdaBoosting)
- アンサンブル学習の内、ブースティング(Boosting)と呼ばれるメタアルゴリズムの基本的なアルゴリズム。
- 一般的にバギングよりも予測性能が高くなりやすいとされている。
- モデルの学習を並列で行えないため、学習時間が長い。
- 正解ラベルの貼り間違えや異常値に弱く、過学習しやすいという欠点を持つ。
- オリジナルのアダブーストは二値分類専用アルゴリズムであるが、それらを多クラス分類タスクや回帰タスクに拡張した改良版アルゴリズムが存在する。

#### アルゴリズム(オリジナルAdaBoost)
1. 使用する機械学習モデルを選択し、学習データにつける重みベクトル・各モデルにつける貢献値を初期化する。
2. 重みを加えたデータで機械学習モデルを学習させる。
3. 学習によって予測しにくいデータに重みを移動させるように重みを更新する。
4. 予測が不正解の位置にある重みの合計を求め、それを元にそのモデルの貢献度を計算・保存する。
5. 貢献度に応じて重みを調整・正規化し、誤差がある程度小さくなるまでステップ2から繰り返す。

<img width="322" alt="original" src="https://user-images.githubusercontent.com/67265109/208430921-be7f1ae5-2746-4f62-9a50-3a68ecadfcb4.png">

#### アルゴリズム(M1)
1. 使用する機械学習モデルを選択し、学習データにつける重みベクトル・各モデルにつける貢献値を初期化する。
2. 重みを加えたデータで機械学習モデルを学習させる。
3. その機械学習モデルの出力から $\frac{正解したデータの重み合計}{不正解したデータの重み合計}$ で定義される0~1の値を持つ $\beta$ を求め、これを先程の予測で正解したデータの重みにかけて小さくする。
4. ブースティングの条件が終わるまで2,3の手順を繰り返す。(終了条件：学習の繰り返し回数が終わる、損失が0になる等)
5. 予測の際は学習した機械学習モデルを予測データを用いて予測させ、その出力地に基づいて分類したクラスに $\log \frac{1}{\beta}$ で求められる各モデルの「貢献値」を足していき、最も貢献値の高いクラスを最終的な予測値とする。

<img width="327" alt="M1" src="https://user-images.githubusercontent.com/67265109/208430938-25486eb4-f604-4811-bcc4-299dd80b7312.png">

#### アルゴリズム(RT)
1. 使用する機械学習モデルを選択し、学習データにつける重みベクトル・各モデルにつける貢献値を初期化する。
2. 重みを加えたデータで機械学習モデルを学習させる。
3. その機械学習モデルの出力の残差の絶対値が予め定めた閾値よりも小さい場合に「正解」、大きい場合に「不正解」として扱い、正解のデータの重みに対して $\frac{正解したデータの重み合計}{不正解したデータの重み合計}$ で定義される0~1の値を持つ $\beta$ の二乗をかけ、重みを小さくする。(二乗である理由は、二乗誤差を最小化するため)
4. 予め定めた回数分、2,3の手順を繰り返す。
5. 予測の際は、各モデルの重み付き平均 $\frac{\sum_{t} \log \frac{1}{\beta_t} ・ f_t(x)}{\sum_{t} \log \frac{1}{\beta_t}}$ となる。

<img width="342" alt="RT" src="https://user-images.githubusercontent.com/67265109/208430955-574da0d3-2863-430c-a8a4-5ca82c70d1a3.png">

#### アルゴリズム(R2)
1. 使用する機械学習モデルを選択し、学習データにつける重みベクトル・各モデルにつける貢献値を初期化する。
2. 重みを加えたデータで機械学習モデルを学習させる。
3. その機械学習モデルの出力の残差の絶対値を、それらの値の最大値で割って正規化したものを各データの重みにかけて小さくする。(こうすることで残差の大きい=判断のしにくいデータの重みは大きく、そうでない重みは小さくできる)
4. 損失の値が $\frac{1}{2}$ より大きくなるまで、2,3の手順を繰り返す。
5. 予測の際は、全ての機械学習モデルについて、モデルの出力の値が小さい順番でその貢献値 $\log \frac{1}{\beta}$ を足していき、全貢献値の半分の位置にあるモデルの出力を最終的な出力にする。(こうすることで、重みつき平均よりも対象の「トレンド」にフィットしたモデルを丁度よく選択できると考えられるため)

<img width="335" alt="R2" src="https://user-images.githubusercontent.com/67265109/208430962-41de7c2f-75b6-476c-b599-17125bf9988b.png">



### モデル選択法
- ある複数のモデルから性能の良いモデルをピックアップして使用するアンサンブル学習の一種
- ※今回作成したプログラムでは全てのモデルで同一のデータを用いて学習させているが、実際は学習に用いるデータでモデルを差別化することが考えられる。

#### 交差検証(Cross Validation Select)
- データをK個に分割し、その内の1つをテストデータに設定して予測精度評価をK回行うモデル評価方法であるクロスバリデーション(KFold法)を用いてモデルを評価し、最も良いモデルを選択する手法。

##### アルゴリズム
1. 複数の学習器を用意する。
2. それらを個別にクロスバリデーションを用いて予測精度を評価し、最も精度の良いモデルを一つ選択する。


#### 情報量基準による選択法(Information Criterion Select)
- 情報量基準という評価指標を用いてモデルを評価し、最も性能が良いモデルを選択する手法。
- メジャーな情報量基準として、赤池情報量基準(AIC)とベイズ情報量基準(BIC)がある。
  - AIC: モデルの予測性能に加えて、モデルの複雑さを考慮した評価指標( $- 2\log{L} + 2k$ )
  - BIC: モデルの予測性能に加えて、AICよりもシンプルなモデルをより高く評価する評価指標( $- 2\log{L} + k\log{n}$ )
  - $k：パラメータ数(説明変数の種類数)、L：尤度関数、n：サンプルサイズ$
- モデル選択を**モデル自体の評価**を用いて定量的に行うことができる手法となっている。
- 参考：http://www.radio3.ee.uec.ac.jp/ronbun/TR_YK_048_AIC.pdf

##### アルゴリズム
1. 複数の学習器を用意し、評価に用いる情報量基準の種類を決定する。
2. それらを個別に情報量基準を用いて評価し、最も精度の良いモデルを一つ選択する。


#### バンピング(Bumping)
- バギングと同様にして学習器を複数作り、各学習器で訓練データの予測精度を調べて最も精度の良いモデルを一つだけ選択する手法。
- 一見にして意味がないように思えるが、ブートストラッピングによって予測にとって害悪なデータを排除したモデルを生成する可能性があり、そのモデルは比較的性能が良くなるはずなのでメリットがある。

##### アルゴリズム
1. バギングを用いて学習器を複数個作成する。
2. それらを個別にクロスバリデーションを用いて評価し、最も精度の良いモデルを一つ選択する。
3. 予測の際は、2で選択したモデル単体での予測となる。


### モデル平均法
- ある複数のモデルの出力をまとめることで性能の向上を図るアンサンブル学習の一種

#### ゲーティング(Gating)

#### スタッキング(Stacking)
参考：https://atmarkit.itmedia.co.jp/ait/articles/2112/02/news016.html

#### NFold平均

#### Smoothed-BIC

#### ブレンディング(Blending)
- スタッキングは評価にKFoldを用いるのに対して、それをホールドアウトでやる方法。実装がシンプルになるが過学習気味になるという特徴がある。
参考：https://atmarkit.itmedia.co.jp/ait/articles/2112/02/news016.html



### バギングをブースティングしてスタッキングする（？）


### XGBoost


### LightGBM


### Catboost




## 参考文献
- 作ってわかる! アンサンブル学習アルゴリズム入門、坂本俊之、C&R研究所(2019)

![Unknown](https://user-images.githubusercontent.com/67265109/207372585-25c2cedf-cfc0-40f9-876c-74790433cb08.jpeg)
