# K-Nearest Neighbor(K近傍法)
## 概要
機械学習アルゴリズムの一種であるK近傍法について、分類と回帰の両方をPythonで実装しました。

## リファレンス
### KNN
- あるテストデータについて、学習データと最も類似しているK個のインスタンスを参照して予測する機械学習アルゴリズムの一種。
- 特定の確率分布によらないため、ノンパラメトリックな手法である。
- 類似度の尺度にはいくつか種類がある。(本プログラムでは4種類を実装)
  - ユークリッド距離: 定規で測るような、私たちが普段使っている「距離」のこと。
$$d(p,q) = \sqrt{\sum_{i=1}^{n}(p_i-q_i)^2}$$
  - マンハッタン距離: 「各座標」の差の絶対値の総和。マス目の外側の道を通る距離として考えれば良い。
$$d(p,q) = |\sum_{i=1}^{n}(p_i-q_i)|$$
  - マハラノビス距離: 無次元数の距離。ある変数間に相関がある時、相関が強い方向の距離は実際の距離よりも相対的に短くする。
    - ※本プログラムではマハラノビス距離の計算にて平均値の代わりに各インスタンスの同特徴量の値を用いているため、定義が若干異なる。
$$Dm(x) = \sqrt{(x-\mu)^T (\sum_{})^{-1} (x-\mu)}$$
  - チェビシェフ距離: 各座標の差（の絶対値）の最大値。斜めに移動するという概念を縦横に移動するイメージ。
$$d(p,q) := max(|p_i-q_i|)$$
![SnapCrab_NoName_2019-2-24_16-38-53_No-00](https://user-images.githubusercontent.com/67265109/205422244-016fdff2-c804-4461-91d0-9fc8922334bf.png)

- 予測対象は分類/回帰の両方に対応できる。
  - 分類: 類似するK個のインスタンスの属する目的変数クラスの**多数決投票**の結果。
  - 回帰: 類似するK個のインスタンスの目的変数の値の**平均値**。


## 参考資料
- 大学の講義資料
- [ディープラーニングで用いられる6つの距離計算](https://sitest.jp/blog/?p=6784)
- [このデータセットにはどの距離を用いればよいの？？～ユークリッド距離・マンハッタン距離・チェビシェフ距離・マハラノビス距離～](https://datachemeng.com/use_of_distance/)
