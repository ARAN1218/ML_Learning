# XAI(eXplainable Artificial Intelligence)

## 概要
ブラックボックスな機械学習を「解釈する」技術を実装しました。

## リファレンス
### PFI(Permutation Feature Importance)
- ある特徴量を**シャッフル**して予測した際の誤差の増加量・増加率を特徴量の重要度として定義したもの。
- 「**本当に重要な特徴量ならば、適当にシャッフルされた場合に予測値に大きな影響を与えるだろう**」という考えから成り立つ。

#### メリット
- この値を見ることで、「**ある機械学習モデルにおいてどの特徴量を予測に大きく活用しているか**」が分かる。
- どんな機械学習モデルに対しても適用可能である。(モデル非依存)
- モデルの学習自体を繰り返さないため、比較的計算負荷が低い。
- PFIの計算に用いるデータは、モデルがよく汎化されている場合は学習・テストデータのどちらを使っても問題ない。
#### デメリット
- あくまでモデルの振る舞い(モデルの予測値と特徴量との関係)を見ているのであって、因果関係(目的変数自体と特徴量との関係)について言及できるものではないことに注意が必要である。
- モデルの振る舞いとして強い相関の示唆が出たとしても、真に重要な特徴量がモデルに組み込まれていない等の疑似相関に注意が必要である。
- 特徴量間で相関性がある場合は、重要度の食い合いが発生して計算がおかしくなってしまう。
  - 該当する特徴量を一つのグループにまとめて値をシャッフルする等の対策を取る必要がある。→GPFIで克服

#### 求め方
1. K個の特徴量 $X_0,X_1...X_k$ を用いて学習させた任意の機械学習モデル $f$ を用意し、テストデータでベースラインとなる予測値を出力する。
2. テストデータのある特徴量 $X_0$ の値のみを無作為にシャッフルし、このデータで同モデルを用いて予測値を出す。
3. 1と2の出力を比較し、予測誤差の増加量・増加率を計算し、これを特徴量 $X_0$ の特徴量重要度とする。
4. 2と3の工程を何回か行い、特徴量重要度の平均を取ると良い。
5. 残りの特徴量 $X_1,X_2...X_k$ についても2~4の工程を行い、特徴量重要度が出揃った時点で各特徴量の重要度を比較分析する。

![Unknown](https://user-images.githubusercontent.com/67265109/205437514-79fd972f-9b3a-4e11-98fb-0b6c6610bf2d.png)


### LOCOFI(Leave One Covariate Out Feature Importance)
- ある特徴量を**削除**して予測した際の誤差の増加量・増加率を特徴量の重要度として定義したもの。
- 「**本当に重要な特徴量ならば、その特徴量が削除された場合に予測値に大きな影響を与えるだろう**」という考えから成り立つ。

#### メリット
- この値を見ることで、「**ある目的変数においてどの特徴量が予測に大きく活用しているか**」が分かる。
- どんな機械学習モデルに対しても適用可能である。(モデル非依存)
- LOCOFIの計算に用いるデータは、モデルがよく汎化されている場合は学習・テストデータのどちらを使っても問題ない。
#### デメリット
- PFIと違ってモデル自体を変えてしまっているため、全特徴量を考慮したモデルにおける振る舞いについては言及できない。
- モデルの学習自体を繰り返すため、比較的計算負荷が高い。
- あくまで目的変数と特徴量との予測における関係を見ているのであって、因果関係(目的変数自体と特徴量自体との関係)について言及できるものではないことに注意が必要である。
- モデルの振る舞いとして強い相関の示唆が出たとしても、真に重要な特徴量がモデルに組み込まれていない等の疑似相関に注意が必要である。
- 特徴量間で相関性がある場合は、重要度の多重共線性が発生して計算がおかしくなってしまう。
  - 該当する特徴量を一つのグループにまとめて値をシャッフルする等の対策を取る必要がある。→GPFIで克服

#### 求め方
1. K個の特徴量 $X_0,X_1...X_k$ を用いて学習させた任意の機械学習モデル $f$ を用意し、テストデータでベースラインとなる予測値を出力する。
2. 学習・テストデータのある特徴量 $X_0$ の値のみを削除し、これらのデータでモデルを再学習・予測値を出す。
3. 1と2の出力を比較し、予測誤差の増加量・増加率を計算し、これを特徴量 $X_0$ の特徴量重要度とする。
4. 残りの特徴量 $X_1,X_2...X_k$ についても2~3の工程を行い、特徴量重要度が出揃った時点で各特徴量の重要度を比較分析する。

![Unknown](https://user-images.githubusercontent.com/67265109/205438595-681a50fd-6a5c-4ef2-9cd3-1808b35a8a12.png)


### GPFI(Grouped PFI)
- ある特徴量群を**まとめてシャッフル**して予測した際の誤差の増加量・増加率を特徴量の重要度として定義したもの。
- 「**本当に重要な特徴量ならば、適当にシャッフルされた場合に予測値に大きな影響を与えるだろう**」という考えから成り立つ。

#### メリット
- この値を見ることで、「**ある機械学習モデルにおいてどの特徴量を予測に大きく活用しているか**」が分かる。
- PFIと違い、強い相関のある特徴量をまとめてシャッフルすることで重要度の多重共線性を回避できる。
- 多重共線性の他にも、特徴量をまとめた方が解釈性の上がる場合や、OneHotEncoding等でカテゴリカルデータをまとめる場合にも役立つ。
- どんな機械学習モデルに対しても適用可能である。(モデル非依存)
- モデルの学習自体を繰り返さないため、比較的計算負荷が低い。
- GPFIの計算に用いるデータは、モデルがよく汎化されている場合は学習・テストデータのどちらを使っても問題ない。
#### デメリット
- あくまでモデルの振る舞い(モデルの予測値と特徴量との関係)を見ているのであって、因果関係(目的変数自体と特徴量との関係)について言及できるものではないことに注意が必要である。
- まとめる特徴量群の選定は、予め自分がEDA等で探索して決定しておかなければならない。

#### 求め方
1. K個の特徴量 $X_0,X_1...X_k$ を用いて学習させた任意の機械学習モデル $f$ を用意し、テストデータでベースラインとなる予測値を出力する。
2. テストデータの指定した特徴量群 $[X_{k1},X_{k2}$ の値をまとめて無作為にシャッフルし、このデータで同モデルを用いて予測値を出す。
3. 1と2の出力を比較し、予測誤差の増加量・増加率を計算し、これを特徴量 $[X_{k1},X_{k2}$ の特徴量重要度とする。
4. 2と3の工程を何回か行い、特徴量重要度の平均を取ると良い。
5. 残りの指定した特徴量群 $[X_1,X_2...X_k]$ についても2~4の工程を行い、特徴量重要度が出揃った時点で各特徴量の重要度を比較分析する。

![Unknown](https://user-images.githubusercontent.com/67265109/205440193-08b0171e-4788-48dc-8b89-3ff7e697a08c.png)


### PDP(Partial Dependence Plot)
- ある特徴量と目的変数の関係を、**他の特徴量を平均値で固定する仮定を置いた上で**一対一で可視化したもの。
- 全てのインスタンスを集約して平均値を可視化する。

#### メリット
- ある特徴量の推移と目的変数の値の推移を対応付けて、目的変数の具体的な変化を一本の線で確認できるため、ある特徴量の影響力の大きさを非常に直感的に理解できる。
- 目的変数と特徴量が非線形の関係にあっても、それをある程度考慮した出力が得られる。
- 出力自体はある特徴量と目的関数の一対一の関係だが、モデルに組み込んだ全ての変数の影響を考慮した出力が得られる。
- どんな機械学習モデルに対しても適用可能である。(モデル非依存)
#### デメリット
- モデルの予測値との平均的な関係性として集約してしまっているため、インスタンス毎の細かな違いを単体で確認できない。→ICEで克服
- あくまでモデルの振る舞い(モデルの予測値と特徴量との関係)を見ているのであって、因果関係(目的変数自体と特徴量との関係)について言及できるものではないことに注意が必要である。
- ある特徴量のプロットする範囲によっては、現実として存在しない範囲まで計算してしまい、結果としておかしなものになってしまう可能性がある。
  - ex.) 男女を0/1で管理している特徴量において、値が0.5の時の目的変数の値までプロットしてしまう。

#### 求め方
1. K個の特徴量 $X_0,X_1...X_k$ を用いて学習させた任意の機械学習モデル $f$ を用意する。
2. テストデータにおいて興味のある特徴量 $X_0$ **以外**を平均値に置き換える。
3. 2のデータにおいて、興味のある特徴量 $X_0$ を任意の範囲(その特徴量の最小値-最大値等)である程度連続的に置き換えつつ予測させ、全ての出力の**平均値**を保管する。
4. 3で得られた出力をx軸を特徴量 $X_0$ の値、y軸を出力の値とした折れ線グラフにプロットし、傾向を分析する。

![Unknown](https://user-images.githubusercontent.com/67265109/205443699-f69bb9c9-6a67-4344-83f1-438fac7c9601.png)


### ICE(Individual Conditional Expectation)
- ある特徴量と目的変数の関係を、**他の特徴量を平均値で固定する仮定を置いた上で**一対一で可視化したもの。
- 全てのインスタンスを集約せずに個別で一本一本可視化する。

#### メリット
- ある特徴量の推移と目的変数の値の推移を対応付けて、目的変数の具体的な変化をインスタンス毎に確認できるため、インスタンスの違いによる**交互作用**等の目的変数の細かい動きをチェックできる。
- 目的変数と特徴量が非線形の関係にあっても、それをある程度考慮した出力が得られる。
- 出力自体はある特徴量と目的関数の一対一の関係だが、モデルに組み込んだ全ての変数の影響を考慮した出力が得られる。
- どんな機械学習モデルに対しても適用可能である。(モデル非依存)
#### デメリット
- モデルの予測値とのインスタンス毎の関係性として集約してしまっているため、直感的な理解が難しい→PDP,CPDで克服
- あくまでモデルの振る舞い(モデルの予測値と特徴量との関係)を見ているのであって、因果関係(目的変数自体と特徴量との関係)について言及できるものではないことに注意が必要である。
- ある特徴量のプロットする範囲によっては、現実として存在しない範囲まで計算してしまい、結果としておかしなものになってしまう可能性がある。
  - ex.) 男女を0/1で管理している特徴量において、値が0.5の時の目的変数の値までプロットしてしまう。

#### 求め方
1. K個の特徴量 $X_0,X_1...X_k$ を用いて学習させた任意の機械学習モデル $f$ を用意する。
2. テストデータにおいて興味のある特徴量 $X_0$ **以外**を平均値に置き換える。
3. 2のデータにおいて、興味のある特徴量 $X_0$ を任意の範囲(その特徴量の最小値-最大値等)である程度連続的に置き換えつつ予測させ、全ての出力を**個別で**保管する。
4. 3で得られた出力をx軸を特徴量 $X_0$ の値、y軸を出力の値とした折れ線グラフにプロットし、傾向を分析する。

![Unknown](https://user-images.githubusercontent.com/67265109/205443692-bf9deeb2-9744-4fd9-adf0-df69de60d5b3.png)


### PDP&ICE
- PDPとICEを同時にプロットしたもの。

#### メリット
- PDPにより全体の動きが、ICEによりインスタンス毎の交互作用の動きが分かり、読み取れる情報量が多くなった。
- 目的変数と特徴量が非線形の関係にあっても、それをある程度考慮した出力が得られる。
- 出力自体はある特徴量と目的関数の一対一の関係だが、モデルに組み込んだ全ての変数の影響を考慮した出力が得られる。
- どんな機械学習モデルに対しても適用可能である。(モデル非依存)
#### デメリット
- あくまでモデルの振る舞い(モデルの予測値と特徴量との関係)を見ているのであって、因果関係(目的変数自体と特徴量との関係)について言及できるものではないことに注意が必要である。
- ある特徴量のプロットする範囲によっては、現実として存在しない範囲まで計算してしまい、結果としておかしなものになってしまう可能性がある。
  - ex.) 男女を0/1で管理している特徴量において、値が0.5の時の目的変数の値までプロットしてしまう。

#### 求め方
1. PDPとICEをそれぞれ求める。
2. PDPとICEを色分けして折れ線グラフにプロットする。

![Unknown](https://user-images.githubusercontent.com/67265109/205443681-18daec16-f444-4a9f-b77c-78203aaca8a9.png)


### CPD(Conditional Partial Dependence)
- ある特徴量と目的変数の関係を、**他の特徴量を平均値で固定する仮定を置いた上で**一対一で可視化したもの。
- ある特徴量で条件付けしてインスタンスをグループ分けして可視化する。

#### メリット
- ある特徴量で条件付けしてインスタンスをグループ分けする事により、ICEよりも交互作用をより分かりやすく可視化できる。
- 目的変数と特徴量が非線形の関係にあっても、それをある程度考慮した出力が得られる。
- 出力自体はある特徴量と目的関数の一対一の関係だが、モデルに組み込んだ全ての変数の影響を考慮した出力が得られる。
- どんな機械学習モデルに対しても適用可能である。(モデル非依存)
#### デメリット
- グルーピングに用いる特徴量は予めEDA等で探索・決定しなければならない。
- あくまでモデルの振る舞い(モデルの予測値と特徴量との関係)を見ているのであって、因果関係(目的変数自体と特徴量との関係)について言及できるものではないことに注意が必要である。
- ある特徴量のプロットする範囲によっては、現実として存在しない範囲まで計算してしまい、結果としておかしなものになってしまう可能性がある。
  - ex.) 男女を0/1で管理している特徴量において、値が0.5の時の目的変数の値までプロットしてしまう。

#### 求め方
1. K個の特徴量 $X_0,X_1...X_k$ を用いて学習させた任意の機械学習モデル $f$ を用意する。
2. テストデータにおいてグルーピングに用いる特徴量を参照してある要素に該当するインスタンスのみを抽出する。
3. 2のデータにおいて、興味のある特徴量 $X_0$ **以外**を平均値に置き換える。
4. 3のデータにおいて、興味のある特徴量 $X_0$ を任意の範囲(その特徴量の最小値-最大値等)である程度連続的に置き換えつつ予測させ、全ての出力を**個別で**保管する。
5. 2~4の工程をグルーピング数だけ行い、得られた出力をx軸を特徴量 $X_0$ の値、y軸を出力の値とした折れ線グラフにグループ毎に分けてプロットし、傾向を分析する。

![Unknown](https://user-images.githubusercontent.com/67265109/205443929-72c2c183-644a-48d6-921a-4b922cd80a9f.png)


### SHAP(SHapley Additive exPlanations)
- あるインスタンスについて、その予測値に対する各特徴量の「貢献度」を特徴量重要度と定義したものである。
- あるインスタンスがその予測値になった「定量的な理由」を提示してくれる。
- 元は協力ゲーム理論のアルバイトゲーム問題でのShaplay値を応用したものである。

#### メリット
- SHAP値自体が目的変数の動きの値を表すため、原理さえ理解していれば分析者にとって分かりやすい指標となる。
- 適切な粒度で集計・可視化を行うことで、各インスタンスの貢献度に着目したミクロな分析から、データ全体の特徴量の影響を理解するマクロな分析までカバーできる。
- どんな機械学習モデルに対しても適用可能である。(モデル非依存)
#### デメリット
- あるインスタンスにおける「なぜこの予測値になったのか」は分かるが、「特徴量が動いた時の目的変数の動き」までは分からない。
  - この点に関してはICEでカバーできる。
- 理論面が相対的に難しく、プレゼン等をする際に専門家から理解を得にくい側面がある可能性がある。
  - PDP等の分かりやすい手法でカバーすることも考えられる。
- 取り扱うデータの各インスタンスについて、特徴量の全組み合わせに対して計算する必要があり、それらが多いと組み合わせ爆発により計算時間が膨大になってしまう。
  - SHAPを計算するインスタンスの数を絞る等の工夫が必要。

#### 求め方
1. K個の特徴量 $X_0,X_1...X_k$ を用いて学習させた任意の機械学習モデル $f$ を用意する。
2. 予測の理由が知りたいテストデータのあるインスタンス $x_0$ に着目する。
3. 全ての特徴量が分かっていない状況として、全てのテストデータの予測値の平均値を計算する。
4. ある任意の特徴量の組み合わせ $[X_0,X_1...X_k]$ が分かっていない状況として、あるインスタンス $x_0$ の該当の特徴量の組み合わせを、他の行での値に上書きして予測させた平均値を計算する。
5. 全ての特徴量が分かっている状況として、あるインスタンス $x_0$ のそのままの予測値を計算する。
6. 3~5の工程で計算した結果について、**分かっている特徴量が増えていく流れの組み合わせの引き算**を全て実施し、特徴量を加えたタイミングの増加分をその特徴量の貢献分として区別してそれぞれ平均を取る。
  - ex.) 特徴量が $[X_0, X_1]$ の2つだった場合、特徴量 $X_0$ の貢献分として $φ→[X_0], [X_1]→[X_0, X_1]$ 、特徴量 $X_1$ の貢献分として $φ→[X_1], [X_0]→[X_0, X_1]$ を計算し、それぞれ平均値を取る。
7. 6の計算結果がSHAP値であり、平均値→予測値の値の動きを表している。これを分析の目的に合わせて適切に集計・可視化する。

![Unknown](https://user-images.githubusercontent.com/67265109/205445700-c7de2714-6aeb-4f9d-ac23-ee72788cd322.png)
![Unknown](https://user-images.githubusercontent.com/67265109/205445702-18eb859d-b210-42c0-a896-2295d3d16b28.png)


## 参考文献
- 機械学習を解釈する技術　森下光之助　技術評論社(2021-08-17)
- [Interpretable Machine Learning](https://hacarus.github.io/interpretable-ml-book-ja/)　Christoph Molnar　(2021-05-31)


![Unknown](https://user-images.githubusercontent.com/67265109/202885565-60e3bc42-248b-4bec-9a4e-436c74c439d9.jpeg)
![Unknown](https://user-images.githubusercontent.com/67265109/202885613-a747b1ea-a04d-481c-b023-00605665fe40.jpeg)

